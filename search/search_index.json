{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"whisper-vtt2srt <p>A robust, production-grade library designed to convert WebVTT to SRT, turning messy AI transcripts into clean, usable subtitles.</p> <p>   A post-processing tool designed to clean the output from OpenAI Whisper, YouTube Auto-Captions, and other AI transcription services.      Perfect for TTS pipelines, video dubbing, and dataset preparation. </p> <p> </p>"},{"location":"#why-whisper-vtt2srt","title":"Why whisper-vtt2srt?","text":"<p>Unlike simple regex-based converters, this tool allows for intelligent cleaning strategies specifically engineered to handle the chaotic output of modern AI transcription services like OpenAI Whisper.</p>"},{"location":"#key-features","title":"Key Features \ud83d\ude80","text":"<ul> <li>\ud83d\udee1\ufe0f Stabilization Strategy: Intelligently detects and merges accumulating text blocks (\"Karaoke Effect\").</li> <li>\ud83c\udfb5 Sound Description Removal: Automatically filters out <code>[Music]</code>, <code>[Applause]</code>, etc.</li> <li>\ud83e\uddf9 Glitch Filtering: Removes imperceptible &lt;50ms blocks.</li> <li>\u2728 Smart Normalization: Strips VTT metadata (<code>align:start</code>, <code>&lt;c&gt;</code>, <code>&lt;b&gt;</code>, <code>&lt;i&gt;</code>) and cleans whitespace.</li> <li>\u26a1 Zero Dependencies: Built with pure Python standard library.</li> <li>\ud83d\udd27 Configurable Strictness: Every cleaning step is optional.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install whisper-vtt2srt\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#cli","title":"CLI","text":"<pre><code># Convert a single file\nwhisper-vtt2srt video.vtt\n\n# Convert a folder recursively\nwhisper-vtt2srt ./videos --recursive\n</code></pre>"},{"location":"#python","title":"Python","text":"<pre><code>from whisper_vtt2srt import Pipeline\n\npipeline = Pipeline()\n\nwith open(\"video.vtt\", \"r\", encoding=\"utf-8\") as f:\n    srt_content = pipeline.convert(f.read())\n</code></pre>"},{"location":"CODE_OF_CONDUCT/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the   overall community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or   advances of any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email   address, without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at [INSERT EMAIL ADDRESS]. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"CODE_OF_CONDUCT/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"CODE_OF_CONDUCT/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"CODE_OF_CONDUCT/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"CODE_OF_CONDUCT/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p>"},{"location":"contributing/","title":"Contributing to whisper-vtt2srt","text":"<p>First off, thanks for taking the time to contribute! \u2764\ufe0f</p> <p>All types of contributions are encouraged and valued. See the Table of Contents for different ways to help and details about how this project handles them.</p>"},{"location":"contributing/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Code of Conduct</li> <li>How Can I Contribute?</li> <li>Reporting Bugs</li> <li>Suggesting Enhancements</li> <li>Pull Requests</li> <li>Styleguides</li> </ul>"},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>This project and everyone participating in it is governed by the Code of Conduct. By participating, you are expected to uphold this code.</p>"},{"location":"contributing/#how-can-i-contribute","title":"How Can I Contribute?","text":""},{"location":"contributing/#reporting-bugs","title":"Reporting Bugs","text":"<p>This section guides you through submitting a bug report for whisper-vtt2srt. Following these guidelines helps maintainers and the community understand your report, reproduce the behavior, and find related reports.</p>"},{"location":"contributing/#suggesting-enhancements","title":"Suggesting Enhancements","text":"<p>This section guides you through submitting an enhancement suggestion for whisper-vtt2srt, including completely new features and minor improvements to existing functionality.</p>"},{"location":"contributing/#pull-requests","title":"Pull Requests","text":"<ol> <li>Fork the repo and create your branch from <code>main</code>.</li> <li>Make sure to add tests for any new logic!</li> <li>Ensure the test suite passes (<code>pytest</code>).</li> <li>Ensure your code is formatted with <code>ruff</code>/<code>black</code>.</li> <li>Issue that pull request!</li> </ol>"},{"location":"contributing/#styleguides","title":"Styleguides","text":""},{"location":"contributing/#git-commit-messages","title":"Git Commit Messages","text":"<ul> <li>Use the present tense (\"Add feature\" not \"Added feature\")</li> <li>Use the imperative mood (\"Move cursor to...\" not \"Moves cursor to...\")</li> <li>Limit the first line to 72 characters or less</li> <li>Reference issues and pull requests liberally after the first line</li> </ul>"},{"location":"playground/","title":"Online Playground","text":"<p>Try whisper-vtt2srt directly in your browser!</p> <p>This demo uses PyScript to run the Python library locally within your browser. No data is sent to any server.</p>"},{"location":"release_guide/","title":"Release &amp; Deployment Guide","text":"<p>This project automates the release process using GitHub Actions. Follow these steps to publish a new version of <code>whisper-vtt2srt</code>.</p>"},{"location":"release_guide/#1-one-time-setup-pypi-trusted-publishing","title":"1. One-Time Setup: PyPI Trusted Publishing","text":"<p>We use PyPI's Trusted Publishing (OIDC) to securely publish packages without needing passwords or API tokens.</p> <ol> <li>Go to your PyPI Settings.</li> <li>Scroll to \"Publishing\" and click \"Add a new publisher\".</li> <li>Select GitHub.</li> <li>Fill in the details:<ul> <li>Owner: <code>jorcelinojunior</code></li> <li>Repository: <code>whisper-vtt2srt</code></li> <li>Workflow name: <code>release.yml</code></li> <li>Environment: <code>pypi</code></li> </ul> </li> <li>Click \"Add publisher\".</li> </ol>"},{"location":"release_guide/#2-how-to-publish-a-new-version","title":"2. How to Publish a New Version","text":"<p>When you are ready to release, simply create and push a Git tag:</p> <ol> <li>Update the version: Change the <code>version</code> field in <code>pyproject.toml</code>.</li> <li>Update the Changelog: Add the new version details to <code>CHANGELOG.md</code>.</li> <li>Commit and Tag:</li> </ol> <pre><code>git add pyproject.toml CHANGELOG.md\ngit commit -m \"chore: release v0.1.0\"\ngit tag v0.1.0\ngit push origin main --tags\n</code></pre>"},{"location":"release_guide/#what-happens-next","title":"What happens next?","text":"<ul> <li>The Release workflow will trigger.</li> <li>It runs the full CI suite (<code>pytest</code>, <code>ruff</code>, <code>mypy</code>).</li> <li>If successful, it creates a GitHub Release with automated notes.</li> <li>It publishes the package to PyPI automatically.</li> </ul>"},{"location":"release_guide/#3-manual-release-emergency-only","title":"3. Manual Release (Emergency only)","text":"<p>If you ever need to build and upload manually:</p> <pre><code># Install build tool\npip install build twine\n\n# Build\npython -m build\n\n# Upload\npython -m twine upload dist/*\n</code></pre>"},{"location":"api/batch/","title":"Batch Processing API","text":""},{"location":"api/batch/#whisper_vtt2srt.use_cases.batch.BatchConverter","title":"<code>whisper_vtt2srt.use_cases.batch.BatchConverter</code>","text":"Source code in <code>whisper_vtt2srt/use_cases/batch.py</code> <pre><code>class BatchConverter:\n    def __init__(self, options: Optional[CleaningOptions] = None):\n        self.pipeline = Pipeline(options)\n\n    def convert(self,\n                input_path: str,\n                output_path: Optional[str] = None,\n                recursive: bool = False,\n                encoding: str = \"utf-8\") -&gt; List[str]:\n        \"\"\"Converts a VTT file or a directory of files to SRT.\n\n        Args:\n            input_path: Path to a single `.vtt` file or a directory containing them.\n            output_path: Optional destination path.\n                - If input is a file, this acts as the output filename.\n                - If input is a directory, this acts as the output root directory.\n                - If None, outputs are generated alongside inputs.\n            recursive: If True and input is a directory, processes subdirectories recursively.\n            encoding: The encoding of the input file(s) (e.g., \"utf-8\", \"latin-1\").\n                Defaults to \"utf-8\".\n\n        Returns:\n            List[str]: A list of paths to the generated `.srt` files.\n\n        Raises:\n            UnicodeDecodeError: If a file cannot be decoded with the specified encoding.\n            IOError: If files cannot be read or written.\n        \"\"\"\n        path_obj = Path(input_path)\n        processed_files = []\n\n        if path_obj.is_file():\n            if self._is_vtt(path_obj):\n                result = self._convert_single_file(path_obj, output_path, encoding)\n                processed_files.append(result)\n        elif path_obj.is_dir():\n            if output_path:\n                # If output is specified for a dir input, it might be ambiguous depending on requirement.\n                # Usually batch processing implies outputting to same dir or a specific output dir.\n                # For simplicity/robustness, let's assume output_path is an Output DIRECTORY if input is a dir.\n                out_dir = Path(output_path)\n                out_dir.mkdir(parents=True, exist_ok=True)\n            else:\n                out_dir = None\n\n            files_to_process = self._scan_directory(path_obj, recursive)\n            for file_path in files_to_process:\n                # determine output filename\n                if out_dir:\n                    rel_path = file_path.relative_to(path_obj)\n                    target_srt = out_dir / rel_path.with_suffix(\".srt\")\n                    target_srt.parent.mkdir(parents=True, exist_ok=True)\n                    out_file_str = str(target_srt)\n                else:\n                    out_file_str = None # Let _convert_single_file decide (default: same dir)\n\n                result = self._convert_single_file(file_path, out_file_str, encoding)\n                processed_files.append(result)\n\n        return processed_files\n\n    def _scan_directory(self, root: Path, recursive: bool) -&gt; List[Path]:\n        vtt_files = []\n        if recursive:\n            for path in root.rglob(\"*.vtt\"):\n                vtt_files.append(path)\n        else:\n            for path in root.glob(\"*.vtt\"):\n                vtt_files.append(path)\n        return sorted(vtt_files)\n\n    def _is_vtt(self, path: Path) -&gt; bool:\n        return path.suffix.lower() == \".vtt\"\n\n    def _convert_single_file(self, intput_file: Path, output_file: Optional[str], encoding: str) -&gt; str:\n        # Determine output path if not set\n        if not output_file:\n            output_file = str(intput_file.with_suffix(\".srt\"))\n\n        print(f\"Converting: {intput_file} -&gt; {output_file}\")\n\n        try:\n            with open(intput_file, \"r\", encoding=encoding) as f:\n                content = f.read()\n\n            srt_content = self.pipeline.convert(content)\n\n            with open(output_file, \"w\", encoding=\"utf-8\") as f:\n                f.write(srt_content)\n\n            return output_file\n        except UnicodeDecodeError:\n            print(f\"Error: Failed to decode {intput_file} with encoding '{encoding}'. Try specifying --encoding.\")\n            raise\n        except Exception as e:\n            print(f\"Error processing {intput_file}: {e}\")\n            raise\n</code></pre>"},{"location":"api/batch/#whisper_vtt2srt.use_cases.batch.BatchConverter.convert","title":"<code>convert(input_path, output_path=None, recursive=False, encoding='utf-8')</code>","text":"<p>Converts a VTT file or a directory of files to SRT.</p> <p>Parameters:</p> Name Type Description Default <code>input_path</code> <code>str</code> <p>Path to a single <code>.vtt</code> file or a directory containing them.</p> required <code>output_path</code> <code>Optional[str]</code> <p>Optional destination path. - If input is a file, this acts as the output filename. - If input is a directory, this acts as the output root directory. - If None, outputs are generated alongside inputs.</p> <code>None</code> <code>recursive</code> <code>bool</code> <p>If True and input is a directory, processes subdirectories recursively.</p> <code>False</code> <code>encoding</code> <code>str</code> <p>The encoding of the input file(s) (e.g., \"utf-8\", \"latin-1\"). Defaults to \"utf-8\".</p> <code>'utf-8'</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: A list of paths to the generated <code>.srt</code> files.</p> <p>Raises:</p> Type Description <code>UnicodeDecodeError</code> <p>If a file cannot be decoded with the specified encoding.</p> <code>IOError</code> <p>If files cannot be read or written.</p> Source code in <code>whisper_vtt2srt/use_cases/batch.py</code> <pre><code>def convert(self,\n            input_path: str,\n            output_path: Optional[str] = None,\n            recursive: bool = False,\n            encoding: str = \"utf-8\") -&gt; List[str]:\n    \"\"\"Converts a VTT file or a directory of files to SRT.\n\n    Args:\n        input_path: Path to a single `.vtt` file or a directory containing them.\n        output_path: Optional destination path.\n            - If input is a file, this acts as the output filename.\n            - If input is a directory, this acts as the output root directory.\n            - If None, outputs are generated alongside inputs.\n        recursive: If True and input is a directory, processes subdirectories recursively.\n        encoding: The encoding of the input file(s) (e.g., \"utf-8\", \"latin-1\").\n            Defaults to \"utf-8\".\n\n    Returns:\n        List[str]: A list of paths to the generated `.srt` files.\n\n    Raises:\n        UnicodeDecodeError: If a file cannot be decoded with the specified encoding.\n        IOError: If files cannot be read or written.\n    \"\"\"\n    path_obj = Path(input_path)\n    processed_files = []\n\n    if path_obj.is_file():\n        if self._is_vtt(path_obj):\n            result = self._convert_single_file(path_obj, output_path, encoding)\n            processed_files.append(result)\n    elif path_obj.is_dir():\n        if output_path:\n            # If output is specified for a dir input, it might be ambiguous depending on requirement.\n            # Usually batch processing implies outputting to same dir or a specific output dir.\n            # For simplicity/robustness, let's assume output_path is an Output DIRECTORY if input is a dir.\n            out_dir = Path(output_path)\n            out_dir.mkdir(parents=True, exist_ok=True)\n        else:\n            out_dir = None\n\n        files_to_process = self._scan_directory(path_obj, recursive)\n        for file_path in files_to_process:\n            # determine output filename\n            if out_dir:\n                rel_path = file_path.relative_to(path_obj)\n                target_srt = out_dir / rel_path.with_suffix(\".srt\")\n                target_srt.parent.mkdir(parents=True, exist_ok=True)\n                out_file_str = str(target_srt)\n            else:\n                out_file_str = None # Let _convert_single_file decide (default: same dir)\n\n            result = self._convert_single_file(file_path, out_file_str, encoding)\n            processed_files.append(result)\n\n    return processed_files\n</code></pre>"},{"location":"api/models/","title":"Domain Models API","text":""},{"location":"api/models/#whisper_vtt2srt.domain.models","title":"<code>whisper_vtt2srt.domain.models</code>","text":""},{"location":"api/models/#whisper_vtt2srt.domain.models.SubtitleBlock","title":"<code>SubtitleBlock</code>  <code>dataclass</code>","text":"<p>Represents a single subtitle event containing text and timing.</p> <p>Attributes:</p> Name Type Description <code>index</code> <code>int</code> <p>The sequential index of the subtitle (1-based).</p> <code>start</code> <code>TimeCode</code> <p>When the subtitle appears.</p> <code>end</code> <code>TimeCode</code> <p>When the subtitle disappears.</p> <code>lines</code> <code>List[str]</code> <p>The text content of the subtitle, split by lines.</p> Source code in <code>whisper_vtt2srt/domain/models.py</code> <pre><code>@dataclass\nclass SubtitleBlock:\n    \"\"\"Represents a single subtitle event containing text and timing.\n\n    Attributes:\n        index (int): The sequential index of the subtitle (1-based).\n        start (TimeCode): When the subtitle appears.\n        end (TimeCode): When the subtitle disappears.\n        lines (List[str]): The text content of the subtitle, split by lines.\n    \"\"\"\n    index: int\n    start: TimeCode\n    end: TimeCode\n    lines: List[str] = field(default_factory=list)\n\n    @property\n    def duration_ms(self) -&gt; int:\n        \"\"\"Calculates the duration of the subtitle in milliseconds.\n\n        Returns:\n            int: The duration in ms.\n        \"\"\"\n        return self.end.milliseconds - self.start.milliseconds\n</code></pre>"},{"location":"api/models/#whisper_vtt2srt.domain.models.SubtitleBlock.duration_ms","title":"<code>duration_ms</code>  <code>property</code>","text":"<p>Calculates the duration of the subtitle in milliseconds.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The duration in ms.</p>"},{"location":"api/models/#whisper_vtt2srt.domain.models.TimeCode","title":"<code>TimeCode</code>  <code>dataclass</code>","text":"<p>Represents a specific point in time used for subtitle scheduling.</p> <p>Attributes:</p> Name Type Description <code>milliseconds</code> <code>int</code> <p>The total time in milliseconds.</p> Source code in <code>whisper_vtt2srt/domain/models.py</code> <pre><code>@dataclass(order=True)\nclass TimeCode:\n    \"\"\"Represents a specific point in time used for subtitle scheduling.\n\n    Attributes:\n        milliseconds (int): The total time in milliseconds.\n    \"\"\"\n    milliseconds: int\n\n    @staticmethod\n    def from_str(time_str: str) -&gt; 'TimeCode':\n        \"\"\"Parses a time string into a TimeCode object.\n\n        Supports standard WebVTT formats:\n        - `MM:SS.mmm`\n        - `HH:MM:SS.mmm`\n\n        Args:\n            time_str: The time string to parse (e.g., \"00:01:02.500\").\n\n        Returns:\n            TimeCode: A new instance representing the parsed time.\n        \"\"\"\n        parts = time_str.strip().split(':')\n        seconds_parts = parts[-1].split('.')\n\n        seconds = int(seconds_parts[0])\n        milliseconds = int(seconds_parts[1]) if len(seconds_parts) &gt; 1 else 0\n        minutes = int(parts[-2])\n        hours = int(parts[-3]) if len(parts) &gt; 2 else 0\n\n        total_ms = (hours * 3600000) + (minutes * 60000) + (seconds * 1000) + milliseconds\n        return TimeCode(total_ms)\n\n    def to_srt_string(self) -&gt; str:\n        \"\"\"Formats the timecode for SRT output.\n\n        Returns:\n            str: Time formatted as `HH:MM:SS,mmm`.\n        \"\"\"\n        total_seconds, milliseconds = divmod(self.milliseconds, 1000)\n        minutes, seconds = divmod(total_seconds, 60)\n        hours, minutes = divmod(minutes, 60)\n        return f\"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}\"\n\n    def __str__(self):\n        return self.to_srt_string()\n</code></pre>"},{"location":"api/models/#whisper_vtt2srt.domain.models.TimeCode.from_str","title":"<code>from_str(time_str)</code>  <code>staticmethod</code>","text":"<p>Parses a time string into a TimeCode object.</p> <p>Supports standard WebVTT formats: - <code>MM:SS.mmm</code> - <code>HH:MM:SS.mmm</code></p> <p>Parameters:</p> Name Type Description Default <code>time_str</code> <code>str</code> <p>The time string to parse (e.g., \"00:01:02.500\").</p> required <p>Returns:</p> Name Type Description <code>TimeCode</code> <code>TimeCode</code> <p>A new instance representing the parsed time.</p> Source code in <code>whisper_vtt2srt/domain/models.py</code> <pre><code>@staticmethod\ndef from_str(time_str: str) -&gt; 'TimeCode':\n    \"\"\"Parses a time string into a TimeCode object.\n\n    Supports standard WebVTT formats:\n    - `MM:SS.mmm`\n    - `HH:MM:SS.mmm`\n\n    Args:\n        time_str: The time string to parse (e.g., \"00:01:02.500\").\n\n    Returns:\n        TimeCode: A new instance representing the parsed time.\n    \"\"\"\n    parts = time_str.strip().split(':')\n    seconds_parts = parts[-1].split('.')\n\n    seconds = int(seconds_parts[0])\n    milliseconds = int(seconds_parts[1]) if len(seconds_parts) &gt; 1 else 0\n    minutes = int(parts[-2])\n    hours = int(parts[-3]) if len(parts) &gt; 2 else 0\n\n    total_ms = (hours * 3600000) + (minutes * 60000) + (seconds * 1000) + milliseconds\n    return TimeCode(total_ms)\n</code></pre>"},{"location":"api/models/#whisper_vtt2srt.domain.models.TimeCode.to_srt_string","title":"<code>to_srt_string()</code>","text":"<p>Formats the timecode for SRT output.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Time formatted as <code>HH:MM:SS,mmm</code>.</p> Source code in <code>whisper_vtt2srt/domain/models.py</code> <pre><code>def to_srt_string(self) -&gt; str:\n    \"\"\"Formats the timecode for SRT output.\n\n    Returns:\n        str: Time formatted as `HH:MM:SS,mmm`.\n    \"\"\"\n    total_seconds, milliseconds = divmod(self.milliseconds, 1000)\n    minutes, seconds = divmod(total_seconds, 60)\n    hours, minutes = divmod(minutes, 60)\n    return f\"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}\"\n</code></pre>"},{"location":"api/options/","title":"Cleaning Options API","text":""},{"location":"api/options/#whisper_vtt2srt.domain.options.CleaningOptions","title":"<code>whisper_vtt2srt.domain.options.CleaningOptions</code>  <code>dataclass</code>","text":"<p>Configuration options for the VTT to SRT cleaning pipeline.</p> <p>Attributes:</p> Name Type Description <code>remove_pixelation</code> <code>bool</code> <p>If True, removes the \"karaoke effect\" where text accumulates over multiple blocks (e.g., \"Hello\" -&gt; \"Hello world\"). Defaults to True.</p> <code>remove_glitches</code> <code>bool</code> <p>If True, removes blocks with invisible duration (&lt; 50ms) that cause player flickering. Defaults to True.</p> <code>simplify_formatting</code> <code>bool</code> <p>If True, strips internal formatting tags like <code>&lt;b&gt;</code>, <code>&lt;i&gt;</code>, <code>&lt;c.color&gt;</code>, etc. Defaults to True.</p> <code>remove_metadata</code> <code>bool</code> <p>If True, removes positioning tags often found in VTT (e.g., <code>align:start position:0%</code>). Defaults to True.</p> <code>merge_short_lines</code> <code>bool</code> <p>If True, aggressively merges short lines into single lines. Defaults to False.</p> <code>remove_sound_descriptions</code> <code>bool</code> <p>If True, removes typical sound descriptions like <code>[Music]</code>, <code>[Applause]</code>, <code>[Laughter]</code>, etc. Defaults to True.</p> Source code in <code>whisper_vtt2srt/domain/options.py</code> <pre><code>@dataclass\nclass CleaningOptions:\n    \"\"\"Configuration options for the VTT to SRT cleaning pipeline.\n\n    Attributes:\n        remove_pixelation (bool): If True, removes the \"karaoke effect\" where text accumulates\n            over multiple blocks (e.g., \"Hello\" -&gt; \"Hello world\"). Defaults to True.\n        remove_glitches (bool): If True, removes blocks with invisible duration (&lt; 50ms)\n            that cause player flickering. Defaults to True.\n        simplify_formatting (bool): If True, strips internal formatting tags\n            like `&lt;b&gt;`, `&lt;i&gt;`, `&lt;c.color&gt;`, etc. Defaults to True.\n        remove_metadata (bool): If True, removes positioning tags often found in VTT\n            (e.g., `align:start position:0%`). Defaults to True.\n        merge_short_lines (bool): If True, aggressively merges short lines into single lines.\n            Defaults to False.\n        remove_sound_descriptions (bool): If True, removes typical sound descriptions\n            like `[Music]`, `[Applause]`, `[Laughter]`, etc. Defaults to True.\n    \"\"\"\n    remove_pixelation: bool = True\n    remove_glitches: bool = True\n    simplify_formatting: bool = True\n    remove_metadata: bool = True\n    merge_short_lines: bool = False\n    remove_sound_descriptions: bool = True\n    max_line_length: int = 42\n</code></pre>"},{"location":"api/pipeline/","title":"Pipeline API","text":""},{"location":"api/pipeline/#whisper_vtt2srt.use_cases.pipeline.Pipeline","title":"<code>whisper_vtt2srt.use_cases.pipeline.Pipeline</code>","text":"<p>Orchestrates the full VTT to SRT conversion process.</p> <p>This class combines the parser, the cleaning filters, and the writer into a single flow. It is the main entry point for in-memory conversion.</p> <p>Attributes:</p> Name Type Description <code>options</code> <code>CleaningOptions</code> <p>Configuration for the cleaning filters.</p> <code>parser</code> <code>VttParser</code> <p>The component that reads VTT text.</p> <code>writer</code> <code>SrtWriter</code> <p>The component that builds SRT text.</p> <code>filters</code> <code>List[ContentFilter]</code> <p>A list of filters to apply sequentially.</p> Source code in <code>whisper_vtt2srt/use_cases/pipeline.py</code> <pre><code>class Pipeline:\n    \"\"\"Orchestrates the full VTT to SRT conversion process.\n\n    This class combines the parser, the cleaning filters, and the writer into a\n    single flow. It is the main entry point for in-memory conversion.\n\n    Attributes:\n        options (CleaningOptions): Configuration for the cleaning filters.\n        parser (VttParser): The component that reads VTT text.\n        writer (SrtWriter): The component that builds SRT text.\n        filters (List[ContentFilter]): A list of filters to apply sequentially.\n    \"\"\"\n\n    def __init__(self, options: Optional[CleaningOptions] = None):\n        self.options = options or CleaningOptions()\n        self.parser = VttParser()\n        self.writer = SrtWriter()\n\n        # Register filters\n        self.filters = [\n            SoundDescriptionFilter(),  # Clean sound descriptions first\n            ContentNormalizer(),\n            GlitchFilter(),\n            KaraokeDeduplicator(),\n            ShortLineMerger()\n        ]\n\n    def convert(self, content: str) -&gt; str:\n        \"\"\"Converts raw VTT string content into formatted SRT string content.\n\n        Args:\n            content: The raw text content of a WebVTT file.\n\n        Returns:\n            str: The processed content formatted as SubRip (SRT).\n        \"\"\"\n        # 1. Parse\n        blocks = list(self.parser.parse(content))\n\n        # 2. Clean/Filter\n        for filter_ in self.filters:\n            blocks = filter_.apply(blocks, self.options)\n\n        # 3. Write\n        return self.writer.write(blocks)\n</code></pre>"},{"location":"api/pipeline/#whisper_vtt2srt.use_cases.pipeline.Pipeline.convert","title":"<code>convert(content)</code>","text":"<p>Converts raw VTT string content into formatted SRT string content.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The raw text content of a WebVTT file.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The processed content formatted as SubRip (SRT).</p> Source code in <code>whisper_vtt2srt/use_cases/pipeline.py</code> <pre><code>def convert(self, content: str) -&gt; str:\n    \"\"\"Converts raw VTT string content into formatted SRT string content.\n\n    Args:\n        content: The raw text content of a WebVTT file.\n\n    Returns:\n        str: The processed content formatted as SubRip (SRT).\n    \"\"\"\n    # 1. Parse\n    blocks = list(self.parser.parse(content))\n\n    # 2. Clean/Filter\n    for filter_ in self.filters:\n        blocks = filter_.apply(blocks, self.options)\n\n    # 3. Write\n    return self.writer.write(blocks)\n</code></pre>"}]}